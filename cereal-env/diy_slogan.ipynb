{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIY Cereal Slogans \n",
    "\n",
    "Use a RNN (Recurrent Neural Network) to generate a cereal slogan! This program is based on an adaptation of the information and tutorial described in: https://thepythoncode.com/article/text-generation-keras-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './data/just_slogans.txt'\n",
    "BASENAME = os.path.basename(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 5528\n"
     ]
    }
   ],
   "source": [
    "# get data and prep it, remove case\n",
    "text = open(FILE_PATH, encoding='utf-8').read().lower()\n",
    "\n",
    "# remove punctuation\n",
    "text = text.translate(str.maketrans(\"\", \"\", punctuation))\n",
    "\n",
    "print(f\"text length: {len(text)}\")\n",
    "\n",
    "# create a mapping \n",
    "unique_chars = sorted(list(set(text)))\n",
    "\n",
    "# number of unique chars \n",
    "num_unique = len(unique_chars)\n",
    "\n",
    "# char -> int\n",
    "char_int = {c: i for i, c in enumerate(unique_chars)}\n",
    "\n",
    "# int -> char\n",
    "int_char = {i: c for i, c in enumerate(unique_chars)}\n",
    "\n",
    "# convert all of the text into ints\n",
    "encoded_text = np.array([char_int[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dicts for text gen \n",
    "pickle.dump(char_int, open(f\"./data/{BASENAME}-char_int.pickle\", \"wb\"))\n",
    "pickle.dump(int_char, open(f\"./data/{BASENAME}-int_char.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "subsequence_length = 100\n",
    "batch_size = 128 # memory can read in efficiently if its in bytes\n",
    "epochs = 30\n",
    "\n",
    "# create a dataset object for efficient handling \n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "# # print characters and their integer representations \n",
    "# for char in char_dataset.take(10):\n",
    "#     print(char.numpy(), int_char[char.numpy()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Dataset \n",
    "- split into inputs and targets to expand the dataset\n",
    "- one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bowl a day keeps the bullies away\n",
      "a dish that’s a winner for wartime\n",
      "a is for apple j is for jacks cinnamon toasty applejacks\n",
      "alphabits you know you want them come and have some\n",
      "always after my lucky\n",
      " charms they’re magically delicious\n",
      "applejacks will not be sold to bullies\n",
      "applejacks where the sweet taste of cinnamon is the winnamon\n",
      "ask for them by name\n",
      "because that’s the kind of mom you are\n",
      "bet y\n"
     ]
    }
   ],
   "source": [
    "# build sequences to be the input of the text generation, the output will be a single character that's predicted \n",
    "sequences = char_dataset.batch(2 * subsequence_length + 1, drop_remainder=True)\n",
    "\n",
    "# this is an example of two sequences that will be fed in\n",
    "for sequence in sequences.take(2):\n",
    "    print(''.join([int_char[i] for i in sequence.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a sequence into input, target samples \n",
    "def split_sample(sample):\n",
    "\n",
    "    # basically taking a sequence and putting it into (input, target format)\n",
    "    # ex. subsequence_length = 5, sequence: theyre grrrreat\n",
    "    # (input, target) -> (theyre grr, r)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensors((sample[:subsequence_length], sample[subsequence_length]))\n",
    "    \n",
    "    # repeat this by splitting the sequences even further, going character by character \n",
    "    for i in range(1, (len(sample) - 1) // 2):\n",
    "        input_ = sample[i: i + subsequence_length]\n",
    "        target = sample[i + subsequence_length]\n",
    "\n",
    "        # create a larger dataset by converting into (input, target)\n",
    "        other_ds = tf.data.Dataset.from_tensors((input_, target))\n",
    "        ds = ds.concatenate(other_ds)\n",
    "    return ds\n",
    "\n",
    "# create inputs and targets\n",
    "dataset = sequences.flat_map(split_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for the samples \n",
    "def one_hot_samples(input_, target):\n",
    "    return tf.one_hot(input_, num_unique), tf.one_hot(target, num_unique)\n",
    "\n",
    "dataset = dataset.map(one_hot_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: a bowl a day keeps the bullies away\n",
      "a dish that’s a winner for wartime\n",
      "a is for apple j is for jacks\n",
      "Target:  \n",
      "Input shape: (100, 32)\n",
      "Target shape: (32,)\n",
      "================================================== \n",
      "\n",
      "Input:  bowl a day keeps the bullies away\n",
      "a dish that’s a winner for wartime\n",
      "a is for apple j is for jacks \n",
      "Target: c\n",
      "Input shape: (100, 32)\n",
      "Target shape: (32,)\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print first 2 samples\n",
    "for element in dataset.take(2):\n",
    "    print(\"Input:\", ''.join([int_char[np.argmax(char_vector)] for char_vector in element[0].numpy()]))\n",
    "    print(\"Target:\", int_char[np.argmax(element[1].numpy())])\n",
    "    print(\"Input shape:\", element[0].shape)\n",
    "    print(\"Target shape:\", element[1].shape)\n",
    "    print(\"=\"*50, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split dataset into batches \n",
    "prepped_dataset = dataset.repeat().shuffle(1024).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Model \n",
    "- LSTM Layers \n",
    "- Dense Layer with Softmax Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100, 256)          295936    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100, 256)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 829472 (3.16 MB)\n",
      "Trainable params: 829472 (3.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(subsequence_length, num_unique), return_sequences=True), \n",
    "    Dropout(0.3), \n",
    "    LSTM(256), \n",
    "    Dense(num_unique, activation=\"softmax\")])\n",
    "\n",
    "# define model path \n",
    "model_weights_path = f\"results/{BASENAME}-{subsequence_length}.h5\"\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(prepped_dataset, steps_per_epoch=(len(encoded_text) - subsequence_length) // batch_size, epochs=epochs)\n",
    "\n",
    "# save it!\n",
    "model.save(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocab dictionaries\n",
    "char_int = pickle.load(open(f\"./data/{BASENAME}-char_int.pickle\", \"rb\"))\n",
    "int_char = pickle.load(open(f\"./data/{BASENAME}-int_char.pickle\", \"rb\"))\n",
    "vocab_size = len(char_int)\n",
    "\n",
    "# build model again \n",
    "# building the model\n",
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(subsequence_length, vocab_size), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(256),\n",
    "    Dense(vocab_size, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "# load the optimal weights\n",
    "model.load_weights(f\"results/{BASENAME}-{subsequence_length}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = random.randint(0, len(text) - 50 - 1)\n",
    "generated = ''\n",
    "seed = text[start_index: start_index + 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating text: 100%|██████████| 30/30 [00:02<00:00, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: oney nut cheerios\n",
      "what are you eating nutin’ honey\n",
      "what’s the good word bird\n",
      "what’s new li\n",
      "\n",
      "Generated Text: me an hor taste that’s of lins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = seed\n",
    "n_chars = 30\n",
    "generated = \"\"\n",
    "\n",
    "# generate n_chars \n",
    "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
    "\n",
    "    # make the input sequence\n",
    "    X = np.zeros((1, subsequence_length, vocab_size))\n",
    "    \n",
    "    for t, char in enumerate(seed):\n",
    "        X[0, (subsequence_length - len(seed)) + t, char_int[char]] = 1\n",
    "\n",
    "    # predict the next character\n",
    "    predicted = model.predict(X, verbose=0)[0]\n",
    "\n",
    "    # converting the vector to an integer\n",
    "    next_index = np.argmax(predicted)\n",
    "\n",
    "    # converting the integer to a character\n",
    "    next_char = int_char[next_index]\n",
    "\n",
    "    # add the character to results\n",
    "    generated += next_char\n",
    "\n",
    "    # shift seed and the predicted character\n",
    "    seed = seed[1:] + next_char\n",
    "\n",
    "print(f\"Seed: {s}\\n\")\n",
    "print(f\"Generated Text: {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)\n",
    "\n",
    "Every once in a while it generates text pretty well! But sometimes it just comes out with gibberish. Most likely need more cereal slogan data to get a better result!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cereal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
